{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140fafe4",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "<a href=#one2>1. Meet the Collaborators</a>\n",
    "\n",
    "<a href=#one1>2. Introduction</a>\n",
    "\n",
    "<a href=#onei>3. Problem Statement</a>\n",
    "\n",
    "\n",
    "<a href=#one>4. Importing Packages</a>\n",
    "\n",
    "<a href=#two>5. Loading Data</a>\n",
    "\n",
    "<a href=#three>6. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "\n",
    "<a href=#four>7. Data Engineering</a>\n",
    "\n",
    "<a href=#five>8. Modeling</a>\n",
    "\n",
    "<a href=#six>9. Model Performance</a>\n",
    "\n",
    "<a href=#seven>10. Model Explanations</a>\n",
    "\n",
    "<a href=#threefiv>11. Conclusion</a>\n",
    "\n",
    "<a href=#threefi>12. References</a>\n",
    "\n",
    "<a href=#threefi>13. Kaggle Submission</a>\n",
    "\n",
    "<a href=#threefi>14. Saving Models</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85025e27",
   "metadata": {},
   "source": [
    "## 1. Meet the Colaborators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44310b1",
   "metadata": {},
   "source": [
    "   #### - AbdulMu'izz Okunade\n",
    "   #### - Ruth Favour Ossai\n",
    "   #### - Francis Egah\n",
    "   #### - Lesego Tiro\n",
    "   #### - Michael Benjamin\n",
    "   #### - Haruna Jibrin \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a38a1",
   "metadata": {},
   "source": [
    "### Honour Code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33854d",
   "metadata": {},
   "source": [
    "Honour Code\n",
    "I {TEAM NM1}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code.\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00858e56",
   "metadata": {},
   "source": [
    "<a id=\"one1\"></a>\n",
    "## 2. Introduction\n",
    "\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a158f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aec196c",
   "metadata": {},
   "source": [
    "<a id=\"onei\"></a>\n",
    "## 3.  Problem Statement: Twitter Sentiment Classification\n",
    "\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50801063",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 4. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcea5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Libraries from Sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd391c",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 5. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840948d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test= pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788da2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc52976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df27a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# convert class from numerical to word definition of class\\ndef class_changer(df):\\n    df = df_train\\n    word_class = []\\n    old_class = df['sentiment']\\n    \\n    for class_ in old_class:\\n        if class_ == 2:\\n            word_class.append('News')\\n        elif class_ == 1:\\n            word_class.append('Pro')\\n        elif class_ == 0:\\n            word_class.append('Neutral')\\n        else:\\n            word_class.append('Anti')\\n    df['sentiment'] = word_class\\n    \\n    return df \\ndf_train = class_changer(df_train)\\ndf_test = class_changer(df_test)  \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# convert class from numerical to word definition of class\n",
    "def class_changer(df):\n",
    "    df = df_train\n",
    "    word_class = []\n",
    "    old_class = df['sentiment']\n",
    "    \n",
    "    for class_ in old_class:\n",
    "        if class_ == 2:\n",
    "            word_class.append('News')\n",
    "        elif class_ == 1:\n",
    "            word_class.append('Pro')\n",
    "        elif class_ == 0:\n",
    "            word_class.append('Neutral')\n",
    "        else:\n",
    "            word_class.append('Anti')\n",
    "    df['sentiment'] = word_class\n",
    "    \n",
    "    return df \n",
    "df_train = class_changer(df_train)\n",
    "df_test = class_changer(df_test)  '''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe13161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentiment word'] = df_train.sentiment.apply(lambda x: \"News\" if x ==2 else\"Pro\" if x==1 else \"Neutral\" if x==0 else \"Anti\")\n",
    "df_test['sentiment word'] = df_train.sentiment.apply(lambda x: \"News\" if x ==2 else\"Pro\" if x==1 else \"Neutral\" if x==0 else \"Anti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f4c4a",
   "metadata": {},
   "source": [
    "The train dataset includes all features of the Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422732ed",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 6. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3006f",
   "metadata": {},
   "source": [
    "### 6.1  The INITIAL INSPECTION AND OBSERVATION OF THE TRAIN DATASET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0127f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @RonaldKlain: As Trump decides on Paris, @B...</td>\n",
       "      <td>458845</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @savingoceans: Lack of #climate change acti...</td>\n",
       "      <td>695439</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>“Yet another Trump advisor is clueless on clim...</td>\n",
       "      <td>894382</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @StephenSchlegel: she's thinking about how ...</td>\n",
       "      <td>603318</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>U.S. environmental agency chief says humans co...</td>\n",
       "      <td>554354</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            message  tweetid  \\\n",
       "0           1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1           1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2           2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3           1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "..        ...                                                ...      ...   \n",
       "95          1  RT @RonaldKlain: As Trump decides on Paris, @B...   458845   \n",
       "96          1  RT @savingoceans: Lack of #climate change acti...   695439   \n",
       "97          1  “Yet another Trump advisor is clueless on clim...   894382   \n",
       "98          1  RT @StephenSchlegel: she's thinking about how ...   603318   \n",
       "99          2  U.S. environmental agency chief says humans co...   554354   \n",
       "\n",
       "   sentiment word  \n",
       "0             Pro  \n",
       "1             Pro  \n",
       "2            News  \n",
       "3             Pro  \n",
       "4             Pro  \n",
       "..            ...  \n",
       "95            Pro  \n",
       "96            Pro  \n",
       "97            Pro  \n",
       "98            Pro  \n",
       "99           News  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train Dataset\n",
    "df_train.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33957bdc",
   "metadata": {},
   "source": [
    "The first five rows and the last five rows of the dataset. This is the dataframe used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e80c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid sentiment word\n",
       "0  Europe will now be looking to China to make su...   169760            Pro\n",
       "1  Combine this with the polling of staffers re c...    35326            Pro\n",
       "2  The scary, unimpeachable evidence that climate...   224985           News\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263            Pro\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928            Pro"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc4455",
   "metadata": {},
   "source": [
    "This is the dataframe used to test the model.\n",
    "The Test Data set does not have the sentiment column which is the Target variable. The target varible is predicted in the modelling phase and the results are then compared to the sentiment column in the Train Dataset. This is how the accuracy of the model is measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0488066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'message', 'tweetid', 'sentiment word'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns of the dataset\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cbbb5",
   "metadata": {},
   "source": [
    "These are the columns that make up the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7f28fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data Set\n",
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782eebc",
   "metadata": {},
   "source": [
    "\n",
    "This shows that the shape of the dataframe entails of 15819 rows and 3 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d33f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63276"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of entries in dataset\n",
    "df_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cda32",
   "metadata": {},
   "source": [
    "The dataframe consists of 47457 entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d666a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment             4\n",
       "message           14229\n",
       "tweetid           15819\n",
       "sentiment word        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique values in columns\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868796a9",
   "metadata": {},
   "source": [
    "This is the the number of unique values present in each of the three columns that makeup the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5023cba",
   "metadata": {},
   "source": [
    "### 6.1 Column Datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ad6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   sentiment       15819 non-null  int64 \n",
      " 1   message         15819 non-null  object\n",
      " 2   tweetid         15819 non-null  int64 \n",
      " 3   sentiment word  15819 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 494.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Data information\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d15194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment         0\n",
       "message           0\n",
       "tweetid           0\n",
       "sentiment word    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nullvalues present in each column\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c30cd",
   "metadata": {},
   "source": [
    "As represented above there are no missing values in any of the three feature of the dataset, which means there will not be any neccesary entity replacement in data engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c51c3ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15819</td>\n",
       "      <td>15819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14229</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RT @StephenSchlegel: she's thinking about how ...</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>307</td>\n",
       "      <td>8530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message sentiment word\n",
       "count                                               15819          15819\n",
       "unique                                              14229              4\n",
       "top     RT @StephenSchlegel: she's thinking about how ...            Pro\n",
       "freq                                                  307           8530"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98bafed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most occuring value in sentiment\n",
    "df_train['sentiment'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ba858",
   "metadata": {},
   "source": [
    "The most occuring value in the sentiment column is '1', this is referred to as the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b9f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['sentiment'].hist(figsize=(5,5), xrot=45)\n",
    "plt.xlabel('sentiment')\n",
    "plt.ylabel(' count of sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834938a0",
   "metadata": {},
   "source": [
    "The visual clearly indicates that sentiment 1(Neutral) occurs way more in the sentiment column than 0(pro),-1(News) and 2(Anti). This is the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa20b8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the distribution for dataset.\n",
    "ax = df_train.groupby('sentiment').count().plot(kind='bar', title='Distribution of data',legend=True)\n",
    "ax.set_xticklabels(['News','Pro', 'Neutral', 'Anti'], rotation=0)\n",
    "#ax.set_yticklabels(['Count'], rotation=90)\n",
    "# Storing data in lists.\n",
    "text, sentiment = list(df_train['message']), list(df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f002b53",
   "metadata": {},
   "source": [
    "This illustrates the sentiment entities in the dataset in a more understandable sense, the sentiment values are given meaning with -1 as News, 0 as Pro, 1 as Neutral and 2 as Anti. and the visual clearly shows on how each TweetiD is tied to a tweet Message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a44a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9b3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db63e956",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 7. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccec3a8",
   "metadata": {},
   "source": [
    "**Cleaning and removing URL’s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "151069ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "df_train['message'] = df_train['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "df_test['message'] = df_train['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2954502",
   "metadata": {},
   "source": [
    "**Removing Punctuations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907b65f",
   "metadata": {},
   "source": [
    "Punctuation Removal: \n",
    "In this step, all the punctuations from the text are removed. string library of Python contains some pre-defined list of punctuations such as ‘!”#$%&'()*+,-./:;?@[\\]^_`{|}~’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "864277f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT RawStory Researchers say we have three year...</td>\n",
       "      <td>698562</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TodayinMaker WIRED  2016 was a pivotal year in...</td>\n",
       "      <td>573736</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT SoyNovioDeTodas Its 2016 and a racist sexis...</td>\n",
       "      <td>466954</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesnt think carbon dio...   625221   \n",
       "1          1  Its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  RT RawStory Researchers say we have three year...   698562   \n",
       "3          1  TodayinMaker WIRED  2016 was a pivotal year in...   573736   \n",
       "4          1  RT SoyNovioDeTodas Its 2016 and a racist sexis...   466954   \n",
       "\n",
       "  sentiment word  \n",
       "0            Pro  \n",
       "1            Pro  \n",
       "2           News  \n",
       "3            Pro  \n",
       "4            Pro  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "df_train['message']= df_train['message'].apply(lambda x:remove_punctuation(x))\n",
    "df_test['message']= df_train['message'].apply(lambda x:remove_punctuation(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614bd9c",
   "metadata": {},
   "source": [
    "We can see in the above output, all the punctuations are removed from message and stored in the clean_msg column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d842f",
   "metadata": {},
   "source": [
    "**Lowering the text:**\n",
    "\n",
    "It is one of the most common preprocessing steps where the text is converted into the same case preferably lower case. We are doing this because we don't want `Message` and `message` or any form of its spellings to be read as  different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9c6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['message']= df_train['message'].apply(lambda x: x.lower())\n",
    "df_test['message']= df_train['message'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34486375",
   "metadata": {},
   "source": [
    "We have succesfully converted all the characters to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7100c424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "\n",
    "# Apply tokenization to both test and train data\n",
    "df_train['message'] = df_train['message'].apply(tokeniser.tokenize)\n",
    "df_test['message'] = df_test['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb8117",
   "metadata": {},
   "source": [
    "**Removal of Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5330f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['polyscimajor', 'epa', 'chief', 'doesnt', 'th...</td>\n",
       "      <td>625221</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['its', 'not', 'like', 'we', 'lack', 'evidence...</td>\n",
       "      <td>126103</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['rt', 'rawstory', 'researchers', 'say', 'we',...</td>\n",
       "      <td>698562</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['todayinmaker', 'wired', '2016', 'was', 'a', ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['rt', 'soynoviodetodas', 'its', '2016', 'and'...</td>\n",
       "      <td>466954</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  ['polyscimajor', 'epa', 'chief', 'doesnt', 'th...   625221   \n",
       "1          1  ['its', 'not', 'like', 'we', 'lack', 'evidence...   126103   \n",
       "2          2  ['rt', 'rawstory', 'researchers', 'say', 'we',...   698562   \n",
       "3          1  ['todayinmaker', 'wired', '2016', 'was', 'a', ...   573736   \n",
       "4          1  ['rt', 'soynoviodetodas', 'its', '2016', 'and'...   466954   \n",
       "\n",
       "  sentiment word  \n",
       "0            Pro  \n",
       "1            Pro  \n",
       "2           News  \n",
       "3            Pro  \n",
       "4            Pro  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list = set(stopwords_list)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwords_list])\n",
    "df_train['message'] = df_train['message'].apply(lambda text: cleaning_stopwords(text))\n",
    "df_test['message'] = df_test['message'].apply(lambda text: cleaning_stopwords(text))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab663545",
   "metadata": {},
   "source": [
    "**Cleaning and removing repeating characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f727ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>['rt', 'ezlusztig', 'they', 'took', 'down', 't...</td>\n",
       "      <td>22001</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2</td>\n",
       "      <td>['rt', 'washingtonpost', 'how', 'climate', 'ch...</td>\n",
       "      <td>17856</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>['notiven', 'rt', 'nytimesworld', 'what', 'doe...</td>\n",
       "      <td>384248</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1</td>\n",
       "      <td>['rt', 'sara8smiles', 'hey', 'liberals', 'the'...</td>\n",
       "      <td>819732</td>\n",
       "      <td>Anti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>['rt', 'chetcannon', 'kurteichenwalds', 'clima...</td>\n",
       "      <td>806319</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "15814          1  ['rt', 'ezlusztig', 'they', 'took', 'down', 't...    22001   \n",
       "15815          2  ['rt', 'washingtonpost', 'how', 'climate', 'ch...    17856   \n",
       "15816          0  ['notiven', 'rt', 'nytimesworld', 'what', 'doe...   384248   \n",
       "15817         -1  ['rt', 'sara8smiles', 'hey', 'liberals', 'the'...   819732   \n",
       "15818          0  ['rt', 'chetcannon', 'kurteichenwalds', 'clima...   806319   \n",
       "\n",
       "      sentiment word  \n",
       "15814            Pro  \n",
       "15815           News  \n",
       "15816        Neutral  \n",
       "15817           Anti  \n",
       "15818        Neutral  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "df_train['message'] = df_train['message'].apply(lambda x: cleaning_repeating_char(x))\n",
    "df_test['message'] = df_test['message'].apply(lambda x: cleaning_repeating_char(x))\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138074ce",
   "metadata": {},
   "source": [
    "**Cleaning and removing Numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd59896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>['rt', 'ezlusztig', 'they', 'took', 'down', 't...</td>\n",
       "      <td>22001</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2</td>\n",
       "      <td>['rt', 'washingtonpost', 'how', 'climate', 'ch...</td>\n",
       "      <td>17856</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>['notiven', 'rt', 'nytimesworld', 'what', 'doe...</td>\n",
       "      <td>384248</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1</td>\n",
       "      <td>['rt', 'sarasmiles', 'hey', 'liberals', 'the',...</td>\n",
       "      <td>819732</td>\n",
       "      <td>Anti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>['rt', 'chetcannon', 'kurteichenwalds', 'clima...</td>\n",
       "      <td>806319</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "15814          1  ['rt', 'ezlusztig', 'they', 'took', 'down', 't...    22001   \n",
       "15815          2  ['rt', 'washingtonpost', 'how', 'climate', 'ch...    17856   \n",
       "15816          0  ['notiven', 'rt', 'nytimesworld', 'what', 'doe...   384248   \n",
       "15817         -1  ['rt', 'sarasmiles', 'hey', 'liberals', 'the',...   819732   \n",
       "15818          0  ['rt', 'chetcannon', 'kurteichenwalds', 'clima...   806319   \n",
       "\n",
       "      sentiment word  \n",
       "15814            Pro  \n",
       "15815           News  \n",
       "15816        Neutral  \n",
       "15817           Anti  \n",
       "15818        Neutral  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "\n",
    "#Apply cleaning_number function to train and test data\n",
    "df_train['message'] = df_train['message'].apply(lambda x: cleaning_numbers(x))\n",
    "df_test['message'] = df_test['message'].apply(lambda x: cleaning_numbers(x))\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f374a",
   "metadata": {},
   "source": [
    "**Tokenization:** \n",
    "\n",
    "In this step, the text is split into smaller units. We can use either sentence tokenization or word tokenization based on our problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5a97b",
   "metadata": {},
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df_train['message'] = df_train['message'].apply(tokeniser.tokenize)\n",
    "df_test['message'] = df_test['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60eaa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a296934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['message'] = df_train['message'].apply(lambda x: tokenization(x.lower()))\n",
    "df_test['message'] = df_test['message'].apply(lambda x: tokenization(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd300e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641bb262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[, polyscimajor, epa, chief, doesnt, think, ca...</td>\n",
       "      <td>625221</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[, its, not, like, we, lack, evidence, of, ant...</td>\n",
       "      <td>126103</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[, rt, rawstory, researchers, say, we, have, t...</td>\n",
       "      <td>698562</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[, todayinmaker, wired, was, a, pivotal, year,...</td>\n",
       "      <td>573736</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[, rt, soynoviodetodas, its, and, a, racist, s...</td>\n",
       "      <td>466954</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  [, polyscimajor, epa, chief, doesnt, think, ca...   625221   \n",
       "1          1  [, its, not, like, we, lack, evidence, of, ant...   126103   \n",
       "2          2  [, rt, rawstory, researchers, say, we, have, t...   698562   \n",
       "3          1  [, todayinmaker, wired, was, a, pivotal, year,...   573736   \n",
       "4          1  [, rt, soynoviodetodas, its, and, a, racist, s...   466954   \n",
       "\n",
       "  sentiment word  \n",
       "0            Pro  \n",
       "1            Pro  \n",
       "2           News  \n",
       "3            Pro  \n",
       "4            Pro  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "df_train['message']= df_train['message'].apply(lambda x: stemming_on_text(x))\n",
    "df_test['message']= df_test['message'].apply(lambda x: stemming_on_text(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5caeabf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[, polyscimajor, epa, chief, doesnt, think, ca...</td>\n",
       "      <td>625221</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[, its, not, like, we, lack, evidence, of, ant...</td>\n",
       "      <td>126103</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[, rt, rawstory, researchers, say, we, have, t...</td>\n",
       "      <td>698562</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[, todayinmaker, wired, was, a, pivotal, year,...</td>\n",
       "      <td>573736</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[, rt, soynoviodetodas, its, and, a, racist, s...</td>\n",
       "      <td>466954</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  [, polyscimajor, epa, chief, doesnt, think, ca...   625221   \n",
       "1          1  [, its, not, like, we, lack, evidence, of, ant...   126103   \n",
       "2          2  [, rt, rawstory, researchers, say, we, have, t...   698562   \n",
       "3          1  [, todayinmaker, wired, was, a, pivotal, year,...   573736   \n",
       "4          1  [, rt, soynoviodetodas, its, and, a, racist, s...   466954   \n",
       "\n",
       "  sentiment word  \n",
       "0            Pro  \n",
       "1            Pro  \n",
       "2           News  \n",
       "3            Pro  \n",
       "4            Pro  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lemma.lemmatize(word) for word in data]\n",
    "    return data\n",
    "df_train['message'] = df_train['message'].apply(lambda x: lemmatizer_on_text(x))\n",
    "df_test['message'] = df_test['message'].apply(lambda x: lemmatizer_on_text(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623b2ba",
   "metadata": {},
   "source": [
    "**Separating input feature and Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "878fee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train.message\n",
    "y=df_train.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e45cb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df_test.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe33742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the 80% data for training data and 20% for testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 20, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ecd60dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Appliyng Countvectorizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m countVectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(analyzer\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mmessage) \n\u001b[0;32m----> 3\u001b[0m countVector \u001b[38;5;241m=\u001b[39m \u001b[43mcountVectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Number of reviews has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m words\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(countVector\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], countVector\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(countVectorizer.get_feature_names())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1335\u001b[0m             )\n\u001b[1;32m   1336\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1338\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1341\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m defaultdict()\n\u001b[1;32m   1199\u001b[0m     vocabulary\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;241m=\u001b[39m vocabulary\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m\n\u001b[0;32m-> 1201\u001b[0m analyze \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m j_indices \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1203\u001b[0m indptr \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:436\u001b[0m, in \u001b[0;36m_VectorizerMixin.build_analyzer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partial(_analyze, analyzer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer, decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode)\n\u001b[1;32m    434\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_preprocessor()\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partial(\n\u001b[1;32m    438\u001b[0m         _analyze,\n\u001b[1;32m    439\u001b[0m         ngrams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_char_ngrams,\n\u001b[1;32m    440\u001b[0m         preprocessor\u001b[38;5;241m=\u001b[39mpreprocess,\n\u001b[1;32m    441\u001b[0m         decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar_wb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "#Appliyng Countvectorizer\n",
    "countVectorizer = CountVectorizer(analyzer=df_train.message) \n",
    "countVector = countVectorizer.fit_transform(df_train['message'])\n",
    "print('{} Number of reviews has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
    "#print(countVectorizer.get_feature_names())\n",
    "\n",
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "count_vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87063fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfbdcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e6ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe0b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c71323",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e048e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(dx)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = vectoriser.transform(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5c192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478cec35",
   "metadata": {},
   "source": [
    "**Transforming Dataset using TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d549eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=5000000)\n",
    "vectoriser.fit(X_train.apply(lambda x: ' '.join(x)))\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19736c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X_train = vectoriser.transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "X_test  = vectoriser.transform(X_test.apply(lambda x: ' '.join(x)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71be319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f92ef56b",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 8. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0787fc",
   "metadata": {},
   "source": [
    "Splitting the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05816f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X=df_train['message']\n",
    "\n",
    "# labels\n",
    "y=df_train['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5999e03",
   "metadata": {},
   "source": [
    "Transforming the categorical features (create dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30739120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186f547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5adea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Features\n",
    "#X_transformed = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246962a0",
   "metadata": {},
   "source": [
    "We create an instance of the LogisticRegression() object using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351046e",
   "metadata": {},
   "source": [
    "The parameters consist of the intercept and the coefficients related to the features.These parameters can be used to predict future claims given the features, so we can extract the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec22635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lr.coef_.T, X_transformed.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde586bb",
   "metadata": {},
   "source": [
    "Next we will use the predict method to obtain predictions from our test data observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad587cbd",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 9. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638c475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c11a9b9",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 10. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899074ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f94feaf9",
   "metadata": {},
   "source": [
    "<a id=\"threefiv\"></a>\n",
    "\n",
    "## 11. Conclusion\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont> Back to Table of Contents </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a098586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76c2071d",
   "metadata": {},
   "source": [
    "<a id=\"threefi\"></a>\n",
    "\n",
    "## 12. References\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont> Back to Table of Contents </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20a17f",
   "metadata": {},
   "source": [
    "1.https://heartbeat.comet.ml/exploratory-data-analysis-eda-for-categorical-data-870b37a79b65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8b0d3",
   "metadata": {},
   "source": [
    "2.https://www.kdnuggets.com/2021/03/11-essential-code-blocks-exploratory-data-analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d84c2",
   "metadata": {},
   "source": [
    " <a id=\"threef\"></a>\n",
    "\n",
    "## 13.  Kaggle Submission\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont> Back to Table of Contents </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd22bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment'] = LRmodel.predict(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = df_test[['tweetid', 'sentiment']]\n",
    "load.to_csv('sample_submission_climate.csv', index = False)\n",
    "load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29aa28c",
   "metadata": {},
   "source": [
    "<a id=\"threeif\"></a>\n",
    "\n",
    "## 14 Saving the Models\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont> Back to Table of Contents </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f86a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
